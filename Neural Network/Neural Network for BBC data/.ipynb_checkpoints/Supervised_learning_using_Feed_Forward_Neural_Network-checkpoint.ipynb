{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to find the best way to extract features from text data (BBC News Dataset) and apply supervised machine learning algorithms to predict the label of the news article  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary modules from sklearn, scipy, numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Using feed forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the csv file using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bbc = pd.read_csv('supervisedlearningdataset_13082016.csv', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Refinning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all NaN values in the data loaded to zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converting NaN values in the dataset to 0.\n",
    "for column in bbc.columns:\n",
    "    bbc[column] = bbc[column].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes the Document id column from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# removing document id from dataset\n",
    "bbc = bbc.drop(\"Document id\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# table information.\n",
    "input_neurons = bbc.shape[1]-1\n",
    "inputs = bbc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# colomn names.\n",
    "feature_columns = bbc.columns[0:input_neurons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stores target column name in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "target = \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data in training and test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Code splits the data into training and test sets. With training being 80% of the original dataset and remaining being test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seperating data into features and label\n",
    "y = bbc.pop(target)\n",
    "X = bbc\n",
    "# splitting data into train and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating numpy array from list\n",
    "np_X_train = np.array(X_train)\n",
    "np_X_test = np.array(X_test)\n",
    "np_y_train = np.array(y_train)\n",
    "np_y_test = np.array(y_test)\n",
    "\n",
    "training_set = (np_X_train,np_y_train)\n",
    "test_set = (np_X_test,np_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    \"\"\"Return a 5-dimensional unit vector with a 1.0 in the jth\n",
    "    position and zeroes elsewhere.  This is used to convert a digit\n",
    "    (0...4) into a corresponding desired output from the neural\n",
    "    network.\"\"\"\n",
    "    e = np.zeros((5, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a In particular, ``training_data`` is a list containing 1780\n",
    "# 2-tuples ``(x, y)``.  ``x`` is a 9635-dimensional numpy.ndarray\n",
    "# containing the input feature.  ``y`` is a 5-dimensional\n",
    "# numpy.ndarray representing the unit vector corresponding to the\n",
    "# correct document for ``x``.\n",
    "\n",
    "training_inputs = [np.reshape(x, (9635, 1)) for x in training_set[0]]\n",
    "training_results = [vectorized_result(y) for y in training_set[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = zip(training_inputs, training_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 9635)\n",
      "(1780,)\n",
      "(445, 9635)\n",
      "(445,)\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [np.reshape(x, (9635, 1)) for x in test_set[0]]\n",
    "test_data = zip(test_inputs, test_set[1])\n",
    "\n",
    "print training_set[0].shape\n",
    "print training_set[1].shape\n",
    "print test_set[0].shape\n",
    "print test_set[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#building a net with 3 layers\n",
    "#first layer i.e. input layer has 9673 neurons, second layer i.e. hidden layer has 3 neuron\n",
    "#and last layer i.e. output layer has 5 neurons\n",
    "\n",
    "net = network.Network([input_neurons,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 137 / 445\n",
      "Epoch 1: 156 / 445\n",
      "Epoch 2: 177 / 445\n",
      "Epoch 3: 218 / 445\n",
      "Epoch 4: 245 / 445\n",
      "Epoch 5: 271 / 445\n",
      "Epoch 6: 286 / 445\n",
      "Epoch 7: 329 / 445\n",
      "Epoch 8: 339 / 445\n",
      "Epoch 9: 354 / 445\n",
      "Epoch 10: 371 / 445\n",
      "Epoch 11: 379 / 445\n",
      "Epoch 12: 386 / 445\n",
      "Epoch 13: 393 / 445\n",
      "Epoch 14: 404 / 445\n",
      "Epoch 15: 399 / 445\n",
      "Epoch 16: 402 / 445\n",
      "Epoch 17: 405 / 445\n",
      "Epoch 18: 408 / 445\n",
      "Epoch 19: 405 / 445\n",
      "Epoch 20: 406 / 445\n",
      "Epoch 21: 410 / 445\n",
      "Epoch 22: 409 / 445\n",
      "Epoch 23: 408 / 445\n",
      "Epoch 24: 410 / 445\n",
      "Epoch 25: 410 / 445\n",
      "Epoch 26: 411 / 445\n",
      "Epoch 27: 412 / 445\n",
      "Epoch 28: 409 / 445\n",
      "Epoch 29: 409 / 445\n"
     ]
    }
   ],
   "source": [
    "#running stochastic gradient descent algorithm\n",
    "net.SGD(training_data, 30, 10, 3.0,test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
